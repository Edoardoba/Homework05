{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build the graph\n",
    "\n",
    "We had to build the graph properly and provide basic informations such as:\n",
    "\n",
    "   * If it is direct or not\n",
    "   * The number of nodes\n",
    "   * The number of edges\n",
    "   * The average node degree. Is the graph dense?\n",
    "   \n",
    "\n",
    "We used a package called **networkX** that has been used in the labs with prof Ioannis.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"wiki-topcats-reduced.txt\", create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the built in function of networkX to get all these basics informations. We have **461193** nodes and an impressive **2645247** number of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 461193\\nNumber of edges: 2645247\\nAverage in degree:   5.7357\\nAverage out degree:   5.7357'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph that we deal with is directed graph according to the *\"wiki-topcats-reduced.txt\"*. In this text file, every row is an edge, the two elements are the nodes (source and destination). Some pairs of nodes are shown twice while the source and destination are opposite. Thus,  we decide that this graph is a **directed graph**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461193"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2645247"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this graph is directed , the **average degree** is the number of edges divided by the number nodes: \n",
    "\n",
    "$$Average \\ degree = \\frac{the \\ number \\ of \\ edges}{the \\ number \\ of \\ nodes}$$\n",
    "\n",
    "To retrieve this information we just had to use the followinf networkX functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.735661642739591"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_edges() / G.number_of_nodes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last information we had to provide about this graph is its **density**. The density of a directed graph is defined as:\n",
    "\n",
    "\n",
    "$$Density = \\frac{the \\ number \\ of \\ edges}{the \\ number \\ of \\ nodes(the \\ number \\ of \\ nodes - 1)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2436602635647606e-05\n",
      "1.2436602635647606e-05\n"
     ]
    }
   ],
   "source": [
    "density = G.number_of_edges() / (G.number_of_nodes()* (G.number_of_nodes()- 1))\n",
    "print(density)\n",
    "print(nx.density(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly say that this graph is **not dense**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 461193\\nNumber of edges: 2645247\\nAverage in degree:   5.7357\\nAverage out degree:   5.7357'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We called again the info function just to double-check our results. The **average degree**, number of nodes and edges are the same as the ones we obtained before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# RQ2\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain a _block-ranking_, where the blocks are represented by the categories\n",
    "   \n",
    "   - How to order categories?\n",
    "       1. Pick first category $C_0$\n",
    "       2. compute distance between nodes in the category($C_0$) and nodes of other categories($C_i$)\n",
    "       \n",
    "       $$distance(C_0, C_i)  = median(ShortestPath(C_0, C_i))$$\n",
    "              \n",
    "           - $ShortestPath(C_0, C_i)$ is the set of all the possible shortest paths between the nodes of $C_0$ and $C_i$\n",
    "           - length of a path is given by the sum of the weights of the edges\n",
    "           \n",
    "### Once you obtain the _block-ranking_ vector, we sort the nodes in each category.\n",
    "    \n",
    "   - How to sort the nodes?\n",
    "       1. Compute subgraph induced by $C_0$. For each node compute the sum of the weigths of the in‑edges.\n",
    "          $$score_{article_i} = \\sum_{i\\in{in-edges}} w_i$$ \n",
    "          \n",
    "       2. Extend the graph to the nodes that belong to $C_1$. Thus, for each article in $C_1$ compute the score as before. \n",
    "          **Note** that the in‑edges coming from the previous category,$C_0$, have as weights the score of the node that sends the edge.\n",
    "    \n",
    "       3. Repeat Step2 up to the last category of the ranking. \n",
    "       \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the text files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start importing the files we need. We first import *wiki-topcats-reduced.txt* that contains nodes(source and destinations) and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461193"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the numbe of nodes in this file\n",
    "all_nodes = []\n",
    "with open(\"wiki-topcats-reduced.txt\") as file:\n",
    "    for edge in file:\n",
    "        all_nodes.extend(edge.split())\n",
    "all_nodes = set(all_nodes)\n",
    "\n",
    "# the number of nodes\n",
    "len(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2645247"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = []\n",
    "with open(\"wiki-topcats-reduced.txt\") as file:\n",
    "    for edge in file:\n",
    "        edges.append(edge.split())\n",
    "        \n",
    "# the number of edges\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then computed,to explore properly the data-set, the *distinct* number of sources and destinations in our file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428957"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We want to know how many different sources we have in the above file\n",
    "sources = []\n",
    "for nodes in edges:\n",
    "    sources.append(nodes[0])\n",
    "sources = set(sources)\n",
    "len(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352518"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We want to know how many different destinations we have in the above file\n",
    "destinations = []\n",
    "for nodes in edges:\n",
    "    destinations.append(nodes[1])\n",
    "destinations = set(destinations)\n",
    "destinations = sorted(destinations, key=int)\n",
    "len(destinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then proceeded importing the *wiki-topcats-categories.txt* file that contains all the different categories and all the articles belonging to the. We consider only categories having more than **3500 articles**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a categories dictionary\n",
    "categories0 = {}\n",
    "with open(\"wiki-topcats-categories.txt\") as file:\n",
    "    for category in file:\n",
    "        category = category.strip(\"Category:\").replace(\"\\n\", \"\").replace(\";\", \"\").split()\n",
    "        categories0[category[0]] = category[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract only categories which have 3500 articles\n",
    "categories = {}\n",
    "for k,v in categories0.items():\n",
    "    if len(v) > 3500:\n",
    "        categories[k] = v\n",
    "        \n",
    "# the number of categories that we deal with\n",
    "len(categories.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to consider only articles present in the reduced file. We took the intersection in order to cut out the nodes of which we had no information about. We print out the result to show the numerosity of every category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'English_footballers': 7538,\n",
       " 'The_Football_League_players': 7814,\n",
       " 'Association_football_forwards': 5097,\n",
       " 'Association_football_goalkeepers': 3737,\n",
       " 'Association_football_midfielders': 5827,\n",
       " 'Association_football_defenders': 4588,\n",
       " 'Living_people': 348300,\n",
       " 'Year_of_birth_unknown': 2536,\n",
       " 'Harvard_University_alumni': 5549,\n",
       " 'Major_League_Baseball_pitchers': 5192,\n",
       " 'Members_of_the_United_Kingdom_Parliament_for_English_constituencies': 6491,\n",
       " 'Indian_films': 5568,\n",
       " 'Year_of_death_missing': 4122,\n",
       " 'English_cricketers': 3275,\n",
       " 'Year_of_birth_missing_(living_people)': 28498,\n",
       " 'Rivers_of_Romania': 7729,\n",
       " 'Main_Belt_asteroids': 11660,\n",
       " 'Asteroids_named_for_people': 4895,\n",
       " 'English-language_albums': 4760,\n",
       " 'English_television_actors': 3362,\n",
       " 'British_films': 4422,\n",
       " 'English-language_films': 22463,\n",
       " 'American_films': 15159,\n",
       " 'Fellows_of_the_Royal_Society': 3446,\n",
       " 'People_from_New_York_City': 4614,\n",
       " 'American_Jews': 3411,\n",
       " 'American_television_actors': 11531,\n",
       " 'American_film_actors': 13865,\n",
       " 'Debut_albums': 7561,\n",
       " 'Black-and-white_films': 10759,\n",
       " 'Year_of_birth_missing': 4346,\n",
       " 'Place_of_birth_missing_(living_people)': 5532,\n",
       " 'Article_Feedback_Pilot': 3485,\n",
       " 'American_military_personnel_of_World_War_II': 3720,\n",
       " 'Windows_games': 4025}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for cate,nodes in categories.items():\n",
    "    \n",
    "    # Get only intersection between nodes in category and all nodes\n",
    "    categories[cate] = list(set(nodes).intersection(all_nodes))\n",
    "\n",
    "num_nodes_reduced = {}\n",
    "for cate,nodes in categories.items():\n",
    "    num_nodes_reduced[cate] = len(nodes)\n",
    "\n",
    "# this is the categories and the number of nodes that we will work with\n",
    "num_nodes_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in the homework text, we had to possibility to choose the category in input. We opted to choose the less populated one,**'Year_of_birth_unknown'**, in order to make our computations less heavier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0 = 'Year_of_birth_unknown'\n",
    "all_ci = list(categories.keys())\n",
    "all_ci.remove(c0) #we remove c0 form the list of all the categories in which we have to compute the distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2536"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_c0 = categories[c0] #this are the nodes corresponding to c0 category\n",
    "nodes_c0.sort(key=int)\n",
    "len(nodes_c0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined two functions in order to be able to use picke files. We used that to save the ranked result(our output) in an external file in order to be able to load it up when needed without making all the computations again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file_to_pickle(file, content):\n",
    "    with open(file, \"wb\") as f:\n",
    "        pickle.dump(content, f)\n",
    "        f.close()\n",
    "\n",
    "def read_file_from_pickle(file):\n",
    "    file_content = {}\n",
    "    with open(file, \"rb\") as f:\n",
    "        file_content = pickle.load(f)\n",
    "        f.close()\n",
    "    \n",
    "    return file_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to explore our graph, we decided to use Breadth-first search (BFS). It is an algorithm for traversing or searching tree or graph data structures. It starts at the tree root (or some arbitrary node of a graph) and explores all of the neighbor nodes at the present depth prior to moving on to the nodes at the next depth level. \n",
    "\n",
    "This algorithm has mainly two features(the reasons why we opted to choose this one):\n",
    "\n",
    "*     it uses a queue (First In First Out) instead of a stack (Last In First Out) and\n",
    "*     it checks whether a vertex has been discovered before enqueueing the vertex rather than delaying this check until the vertex is dequeued from the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(Graph, source, destination):\n",
    "    queue = [[source]]  # we take the set of the sources\n",
    "    visited = set()  #we create a set in which we will store all the visited nodes\n",
    "    \n",
    "    if not nx.has_path(Graph, source, destination): #If there is no path between source and destination we return nan\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    while queue:   #While we have some nodes to explore\n",
    "        # Gets the first path in the queue\n",
    "        path = queue.pop(0)\n",
    "\n",
    "        # Gets the last node in the path\n",
    "        vertex = path[-1]\n",
    "\n",
    "        # Checks if we got to the end\n",
    "        if vertex == destination:\n",
    "            return len(path)\n",
    "        # We check if the current node is already in the visited nodes set in order not to recheck it\n",
    "        elif vertex not in visited:\n",
    "            neighbours = list(Graph.neighbors(vertex))\n",
    "            # enumerate all adjacent nodes, construct a new path and push it into the queue\n",
    "            for current_neighbour in neighbours:\n",
    "                new_path = list(path)\n",
    "                new_path.append(current_neighbour)\n",
    "                queue.append(new_path)\n",
    "                \n",
    "            # Mark the vertex as visited\n",
    "            visited.add(vertex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_ranking = {} #This will contain the categories ranked.\n",
    "\n",
    "for ci in all_ci:\n",
    "    # pick one category\n",
    "    nodes_ci = categories[ci]\n",
    "    \n",
    "    #make a subgraph\n",
    "    sub_nodes = nodes_c0 + nodes_ci\n",
    "    H = G.subgraph(sub_nodes)\n",
    "    \n",
    "    # a list to input the shortest path\n",
    "    length = []\n",
    "\n",
    "    for source in nodes_c0:\n",
    "        for destination in nodes_ci:\n",
    "            # compute shortest path\n",
    "            length.append(bfs(H, source, destination))\n",
    "    \n",
    "    # remove nan value\n",
    "    length = [ x for x in length if str(x) != \"nan\"]\n",
    "    # get a median in list and append it to the dictionary\n",
    "    block_ranking[ci] = statistics.median(length)\n",
    "    \n",
    "# sort by value\n",
    "block_ranking = sorted(block_ranking.items(), key = lambda x: x[1])\n",
    "\n",
    "# save this dictionary to avoid costing much time again \n",
    "write_file_to_pickle(\"block_ranking\", block_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having read from the pickle file this is the output of our categories ranked by the median of the shortest path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Major_League_Baseball_pitchers', 2),\n",
       " ('Debut_albums', 2),\n",
       " ('Year_of_death_missing', 3.0),\n",
       " ('Year_of_birth_missing_(living_people)', 3),\n",
       " ('Year_of_birth_missing', 3),\n",
       " ('Place_of_birth_missing_(living_people)', 3),\n",
       " ('Asteroids_named_for_people', 4.5),\n",
       " ('Main_Belt_asteroids', 5),\n",
       " ('British_films', 5),\n",
       " ('Association_football_goalkeepers', 7),\n",
       " ('Article_Feedback_Pilot', 7),\n",
       " ('Rivers_of_Romania', 7.0),\n",
       " ('English_footballers', 8),\n",
       " ('The_Football_League_players', 8.0),\n",
       " ('Association_football_forwards', 8.0),\n",
       " ('Association_football_midfielders', 8.0),\n",
       " ('Association_football_defenders', 8.0),\n",
       " ('English_cricketers', 8.0),\n",
       " ('English_television_actors', 8.0),\n",
       " ('Fellows_of_the_Royal_Society', 8.0),\n",
       " ('American_Jews', 8),\n",
       " ('American_television_actors', 8),\n",
       " ('American_film_actors', 8.0),\n",
       " ('American_military_personnel_of_World_War_II', 8),\n",
       " ('Members_of_the_United_Kingdom_Parliament_for_English_constituencies', 8),\n",
       " ('Living_people', 8.0),\n",
       " ('Indian_films', 9),\n",
       " ('English-language_albums', 9),\n",
       " ('Harvard_University_alumni', 10.0),\n",
       " ('People_from_New_York_City', 11),\n",
       " ('English-language_films', 12.0),\n",
       " ('American_films', 12.0),\n",
       " ('Black-and-white_films', 14.0),\n",
       " ('Windows_games', 24.0)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_ranking = read_file_from_pickle(\"block_ranking\")\n",
    "block_ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load back the *sorted_notes* which contains the nodes sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_block_ranking = [x[0] for x in block_ranking ]\n",
    "categories_block_ranking.insert(0, c0)\n",
    "len(categories_block_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make nested dictionary(key1 : category, key2(value1) : node, value2 :  weight)\n",
    "nodes_rank = {}\n",
    "\n",
    "for idx, category in enumerate(categories_block_ranking):\n",
    "    \n",
    "    # nested dictionary like \n",
    "    # nodes_rank { category { node : weight } }\n",
    "    \n",
    "    nodes_rank[category] = {}\n",
    "    nodes = categories[category]\n",
    "    \n",
    "    # This is only first category\n",
    "    if idx == 0:\n",
    "        \n",
    "        # make subgraph\n",
    "        H = G.subgraph(nodes)\n",
    "        \n",
    "        for node in nodes:\n",
    "            # first set 0 as initial weight\n",
    "            nodes_rank[category][node]  = 0\n",
    "            # find neighbors\n",
    "            neighbors = list(H.neighbors(node))\n",
    "            \n",
    "            for neighbor in neighbors:\n",
    "                # assign weight \n",
    "                # check whether the edge is coming from neighbor to node or not\n",
    "                if nx.has_path(H, neighbor, node):\n",
    "                    nodes_rank[category][node] += 1\n",
    "        \n",
    "    else:\n",
    "        # make subgraph of current category and previous category\n",
    "        sub_nodes = nodes + previous_nodes\n",
    "        H = G.subgraph(sub_nodes)\n",
    "        \n",
    "        for node in nodes:\n",
    "            # first set 0 as initial weight\n",
    "            nodes_rank[category][node]  = 0\n",
    "            # find neighbors\n",
    "            neighbors = list(H.neighbors(node))\n",
    "            \n",
    "            for neighbor in neighbors:\n",
    "                # if the edge comes from PREVIOUS category, add the weight of the node which comes from\n",
    "                if neighbor in previous_nodes and nx.has_path(H, neighbor, node):\n",
    "                    nodes_rank[category][node] += nodes_rank[previous_category][neighbor]\n",
    "                    continue\n",
    "                # if the edge comes from CURRENT category\n",
    "                elif nx.has_path(H, neighbor, node):\n",
    "                    nodes_rank[category][node] += 1\n",
    "                    \n",
    "    # save nodes and category as previous data         \n",
    "    previous_nodes = nodes\n",
    "    previous_category = category\n",
    "\n",
    "# sort values in dictionary\n",
    "for i in range(len(nodes_rank)):\n",
    "    category = categories_block_ranking[i]\n",
    "    nodes_rank[category] = sorted(nodes_rank[category].items(), key = lambda x: x[1], reverse=True)    \n",
    "\n",
    "# save as a pickle file\n",
    "write_file_to_pickle(\"sorted_nodes\", nodes_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_nodes = read_file_from_pickle(\"sorted_nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import also the third file contatining all the names related to the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "listanomi=[]\n",
    "with open('wiki-topcats-page-names.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        l = line.split(' ',1)\n",
    "        listanomi.append(l[1])\n",
    "lista1 = [w.replace('\\n', ' ') for w in listanomi]   #in this list we have all the names cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Major_League_Baseball_pitchers</th>\n",
       "      <th>Debut_albums</th>\n",
       "      <th>Year_of_death_missing</th>\n",
       "      <th>Year_of_birth_missing_(living_people)</th>\n",
       "      <th>Year_of_birth_missing</th>\n",
       "      <th>Place_of_birth_missing_(living_people)</th>\n",
       "      <th>Asteroids_named_for_people</th>\n",
       "      <th>Main_Belt_asteroids</th>\n",
       "      <th>British_films</th>\n",
       "      <th>Association_football_goalkeepers</th>\n",
       "      <th>...</th>\n",
       "      <th>Members_of_the_United_Kingdom_Parliament_for_English_constituencies</th>\n",
       "      <th>Living_people</th>\n",
       "      <th>Indian_films</th>\n",
       "      <th>English-language_albums</th>\n",
       "      <th>Harvard_University_alumni</th>\n",
       "      <th>People_from_New_York_City</th>\n",
       "      <th>English-language_films</th>\n",
       "      <th>American_films</th>\n",
       "      <th>Black-and-white_films</th>\n",
       "      <th>Windows_games</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luis Aparicio</td>\n",
       "      <td>The Emperor of the Bathroom</td>\n",
       "      <td>Don Rowlands</td>\n",
       "      <td>Steve Yeowell</td>\n",
       "      <td>Geoffrey Clarkson</td>\n",
       "      <td>Gordon Haynes</td>\n",
       "      <td>3353 Jarvis</td>\n",
       "      <td>3351 Smith</td>\n",
       "      <td>Bud Flanagan</td>\n",
       "      <td>201011 Blackburn Rovers F.C. season</td>\n",
       "      <td>...</td>\n",
       "      <td>Nic Dakin</td>\n",
       "      <td>Life peer</td>\n",
       "      <td>Patton (film)</td>\n",
       "      <td>Ballad of Easy Rider</td>\n",
       "      <td>Chris Leslie (folk musician)</td>\n",
       "      <td>Critique of Pure Reason</td>\n",
       "      <td>Eleanor and Franklin: The White House Years</td>\n",
       "      <td>List of The Nostalgia Critic episodes</td>\n",
       "      <td>A Night at the Opera (film)</td>\n",
       "      <td>Limbo of the Lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom Seaver</td>\n",
       "      <td>It Was Written</td>\n",
       "      <td>Thomas Engel</td>\n",
       "      <td>Margaret Way</td>\n",
       "      <td>Jane Donnelly</td>\n",
       "      <td>John McKeown (rugby league)</td>\n",
       "      <td>3352 McAuliffe</td>\n",
       "      <td>3355 Onizuka</td>\n",
       "      <td>Q (James Bond)</td>\n",
       "      <td>Peter Clarke (footballer)</td>\n",
       "      <td>...</td>\n",
       "      <td>Julian Ridsdale</td>\n",
       "      <td>James Callaghan</td>\n",
       "      <td>Munna Bhai M.B.B.S.</td>\n",
       "      <td>List of Basement Tapes songs</td>\n",
       "      <td>Powder Alarm</td>\n",
       "      <td>Karl Earl Mundt</td>\n",
       "      <td>Terror in the Aisles</td>\n",
       "      <td>Butch Cassidy and the Sundance Kid</td>\n",
       "      <td>Small Soldiers</td>\n",
       "      <td>Sam &amp; Max Beyond Time and Space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Philadelphia Phillies</td>\n",
       "      <td>Ol' Dirty Bastard</td>\n",
       "      <td>Charlie Davey (footballer)</td>\n",
       "      <td>Lisa Connor</td>\n",
       "      <td>James Gaines</td>\n",
       "      <td>Geoff Wriglesworth</td>\n",
       "      <td>3351 Smith</td>\n",
       "      <td>3353 Jarvis</td>\n",
       "      <td>The Best Man (1964 film)</td>\n",
       "      <td>Kak</td>\n",
       "      <td>...</td>\n",
       "      <td>Stockton South (UK Parliament constituency)</td>\n",
       "      <td>Order of succession</td>\n",
       "      <td>Moojrim</td>\n",
       "      <td>Art Garfunkel</td>\n",
       "      <td>Augustus Lowell</td>\n",
       "      <td>William Warren Barbour</td>\n",
       "      <td>William S. Cowles</td>\n",
       "      <td>Haskell Wexler</td>\n",
       "      <td>Monkey Business (1931 film)</td>\n",
       "      <td>Penumbra: Requiem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pete Rose</td>\n",
       "      <td>The Rest Is History</td>\n",
       "      <td>Harry Clarke (footballer)</td>\n",
       "      <td>Mills &amp; Boon</td>\n",
       "      <td>Don Rowlands</td>\n",
       "      <td>William Banks (rugby league)</td>\n",
       "      <td>3350 Scobee</td>\n",
       "      <td>3352 McAuliffe</td>\n",
       "      <td>For Your Eyes Only (film)</td>\n",
       "      <td>Joe Kinnear</td>\n",
       "      <td>...</td>\n",
       "      <td>Harold Wilson</td>\n",
       "      <td>John Major</td>\n",
       "      <td>Sanjay Leela Bhansali</td>\n",
       "      <td>Harvest Moon (album)</td>\n",
       "      <td>Edgard Varse</td>\n",
       "      <td>Herbert Hoover</td>\n",
       "      <td>Bruce Greenwood</td>\n",
       "      <td>A Night at the Opera (film)</td>\n",
       "      <td>Animal Crackers (film)</td>\n",
       "      <td>Dragon Age: Origins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earned run average</td>\n",
       "      <td>Verizon Wireless Amphitheater (Selma)</td>\n",
       "      <td>Kerry Ashby</td>\n",
       "      <td>Brian Tarquin</td>\n",
       "      <td>Thomas Engel</td>\n",
       "      <td>George Parsons (rugby)</td>\n",
       "      <td>3356 Resnik</td>\n",
       "      <td>3356 Resnik</td>\n",
       "      <td>Liz Fraser</td>\n",
       "      <td>Gianluca Zanetti</td>\n",
       "      <td>...</td>\n",
       "      <td>Secretary of State for Education</td>\n",
       "      <td>Martin Stevens</td>\n",
       "      <td>Zor (film)</td>\n",
       "      <td>I Don't Want to Spoil the Party</td>\n",
       "      <td>Presidency of Thomas Jefferson</td>\n",
       "      <td>United States Ambassador to the United Nations</td>\n",
       "      <td>List of Sundance Film Festival selections</td>\n",
       "      <td>Frank Marshall (film producer)</td>\n",
       "      <td>James Rebhorn</td>\n",
       "      <td>Dungeon Runners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nolan Ryan</td>\n",
       "      <td>Liquid Swords</td>\n",
       "      <td>Jack L. Collins</td>\n",
       "      <td>Catherine Spencer</td>\n",
       "      <td>Kerry Ashby</td>\n",
       "      <td>Israa Abdel Fattah</td>\n",
       "      <td>3355 Onizuka</td>\n",
       "      <td>3350 Scobee</td>\n",
       "      <td>Johnny English</td>\n",
       "      <td>Marko Panteli</td>\n",
       "      <td>...</td>\n",
       "      <td>Labour Government 19451951</td>\n",
       "      <td>John Boyd-Carpenter, Baron Boyd-Carpenter</td>\n",
       "      <td>Rekha</td>\n",
       "      <td>It Was Written</td>\n",
       "      <td>Harry Markowitz</td>\n",
       "      <td>William Maclay (politician)</td>\n",
       "      <td>A Night at the Opera (film)</td>\n",
       "      <td>The Last House on the Left (2009 film)</td>\n",
       "      <td>The Bell Boy</td>\n",
       "      <td>Aquaria (video game)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Derek Lowe</td>\n",
       "      <td>Cliff Burton</td>\n",
       "      <td>Murray Ashby</td>\n",
       "      <td>Glenn Fabry</td>\n",
       "      <td>Murray Ashby</td>\n",
       "      <td>Heather Armitage</td>\n",
       "      <td>2383 Bradley</td>\n",
       "      <td>2383 Bradley</td>\n",
       "      <td>Licence to Kill</td>\n",
       "      <td>Ronnie Wallwork</td>\n",
       "      <td>...</td>\n",
       "      <td>Victor Cavendish, 9th Duke of Devonshire</td>\n",
       "      <td>Edward Leigh</td>\n",
       "      <td>Jayaraj</td>\n",
       "      <td>Across the Universe</td>\n",
       "      <td>Philosophy of logic</td>\n",
       "      <td>Stuart Rothenberg</td>\n",
       "      <td>Gustave Reininger</td>\n",
       "      <td>Golden Globe Award for Best Screenplay</td>\n",
       "      <td>Virginia Fox</td>\n",
       "      <td>Atom Zombie Smasher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Steve Carlton</td>\n",
       "      <td>So Fresh: The Hits of Autumn 2007</td>\n",
       "      <td>Bruce Culpan</td>\n",
       "      <td>Sara Wood (novelist)</td>\n",
       "      <td>Ian Watson (rugby league)</td>\n",
       "      <td>Jeff Fishback</td>\n",
       "      <td>9531 Jean-Luc</td>\n",
       "      <td>9621 Michaelpalin</td>\n",
       "      <td>James Bond Theme</td>\n",
       "      <td>Lee Sharpe</td>\n",
       "      <td>...</td>\n",
       "      <td>Aubrey Jones</td>\n",
       "      <td>Howard Vincent</td>\n",
       "      <td>Udhayanidhi Stalin</td>\n",
       "      <td>Disturbia (song)</td>\n",
       "      <td>Guy Lowell</td>\n",
       "      <td>Howl</td>\n",
       "      <td>Casablanca (film)</td>\n",
       "      <td>Meg Tilly</td>\n",
       "      <td>Norman Z. McLeod</td>\n",
       "      <td>SimCity 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>George Steinbrenner</td>\n",
       "      <td>Echo (Leona Lewis album)</td>\n",
       "      <td>Dmitry Golovanov</td>\n",
       "      <td>Cathy Williams</td>\n",
       "      <td>Bruce Culpan</td>\n",
       "      <td>Lau Kwok Kin</td>\n",
       "      <td>9620 Ericidle</td>\n",
       "      <td>9531 Jean-Luc</td>\n",
       "      <td>Live and Let Die (film)</td>\n",
       "      <td>Patrick Vieira</td>\n",
       "      <td>...</td>\n",
       "      <td>Holborn and St Pancras South (UK Parliament co...</td>\n",
       "      <td>James Barr (politician)</td>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>Revolver (album)</td>\n",
       "      <td>Philosophical progress</td>\n",
       "      <td>EXCOMM</td>\n",
       "      <td>List of Academy Award-winning films</td>\n",
       "      <td>Walt Disney Pictures</td>\n",
       "      <td>The Cat's Meow</td>\n",
       "      <td>Half-Life (video game)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Frank Francisco</td>\n",
       "      <td>Right Round</td>\n",
       "      <td>Donald Adam</td>\n",
       "      <td>Rebecca Winters</td>\n",
       "      <td>Dmitry Golovanov</td>\n",
       "      <td>Robert Engman</td>\n",
       "      <td>9617 Grahamchapman</td>\n",
       "      <td>9620 Ericidle</td>\n",
       "      <td>Goldfinger (film)</td>\n",
       "      <td>Alberto Frison</td>\n",
       "      <td>...</td>\n",
       "      <td>Roy Jenkins</td>\n",
       "      <td>David Howell, Baron Howell of Guildford</td>\n",
       "      <td>Harris Jayaraj</td>\n",
       "      <td>P.S. I Love You (The Beatles song)</td>\n",
       "      <td>Andrew Jackson</td>\n",
       "      <td>Robert Kagan</td>\n",
       "      <td>High Noon</td>\n",
       "      <td>Shawn Wayans</td>\n",
       "      <td>Up and at 'Em</td>\n",
       "      <td>The Phantom of Venice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Major_League_Baseball_pitchers                            Debut_albums  \\\n",
       "0                 Luis Aparicio             The Emperor of the Bathroom    \n",
       "1                    Tom Seaver                          It Was Written    \n",
       "2         Philadelphia Phillies                       Ol' Dirty Bastard    \n",
       "3                     Pete Rose                     The Rest Is History    \n",
       "4            Earned run average   Verizon Wireless Amphitheater (Selma)    \n",
       "5                    Nolan Ryan                           Liquid Swords    \n",
       "6                    Derek Lowe                            Cliff Burton    \n",
       "7                 Steve Carlton       So Fresh: The Hits of Autumn 2007    \n",
       "8           George Steinbrenner                Echo (Leona Lewis album)    \n",
       "9               Frank Francisco                             Right Round    \n",
       "\n",
       "         Year_of_death_missing Year_of_birth_missing_(living_people)  \\\n",
       "0                Don Rowlands                         Steve Yeowell    \n",
       "1                Thomas Engel                          Margaret Way    \n",
       "2  Charlie Davey (footballer)                           Lisa Connor    \n",
       "3   Harry Clarke (footballer)                          Mills & Boon    \n",
       "4                 Kerry Ashby                         Brian Tarquin    \n",
       "5             Jack L. Collins                     Catherine Spencer    \n",
       "6                Murray Ashby                           Glenn Fabry    \n",
       "7                Bruce Culpan                  Sara Wood (novelist)    \n",
       "8            Dmitry Golovanov                        Cathy Williams    \n",
       "9                 Donald Adam                       Rebecca Winters    \n",
       "\n",
       "        Year_of_birth_missing Place_of_birth_missing_(living_people)  \\\n",
       "0          Geoffrey Clarkson                          Gordon Haynes    \n",
       "1              Jane Donnelly            John McKeown (rugby league)    \n",
       "2               James Gaines                     Geoff Wriglesworth    \n",
       "3               Don Rowlands           William Banks (rugby league)    \n",
       "4               Thomas Engel                 George Parsons (rugby)    \n",
       "5                Kerry Ashby                     Israa Abdel Fattah    \n",
       "6               Murray Ashby                       Heather Armitage    \n",
       "7  Ian Watson (rugby league)                          Jeff Fishback    \n",
       "8               Bruce Culpan                           Lau Kwok Kin    \n",
       "9           Dmitry Golovanov                          Robert Engman    \n",
       "\n",
       "  Asteroids_named_for_people Main_Belt_asteroids               British_films  \\\n",
       "0               3353 Jarvis          3351 Smith                Bud Flanagan    \n",
       "1            3352 McAuliffe        3355 Onizuka              Q (James Bond)    \n",
       "2                3351 Smith         3353 Jarvis    The Best Man (1964 film)    \n",
       "3               3350 Scobee      3352 McAuliffe   For Your Eyes Only (film)    \n",
       "4               3356 Resnik         3356 Resnik                  Liz Fraser    \n",
       "5              3355 Onizuka         3350 Scobee              Johnny English    \n",
       "6              2383 Bradley        2383 Bradley             Licence to Kill    \n",
       "7             9531 Jean-Luc   9621 Michaelpalin            James Bond Theme    \n",
       "8             9620 Ericidle       9531 Jean-Luc     Live and Let Die (film)    \n",
       "9        9617 Grahamchapman       9620 Ericidle           Goldfinger (film)    \n",
       "\n",
       "       Association_football_goalkeepers                ...                 \\\n",
       "0  201011 Blackburn Rovers F.C. season                 ...                  \n",
       "1            Peter Clarke (footballer)                 ...                  \n",
       "2                                  Kak                 ...                  \n",
       "3                          Joe Kinnear                 ...                  \n",
       "4                     Gianluca Zanetti                 ...                  \n",
       "5                        Marko Panteli                 ...                  \n",
       "6                      Ronnie Wallwork                 ...                  \n",
       "7                           Lee Sharpe                 ...                  \n",
       "8                       Patrick Vieira                 ...                  \n",
       "9                       Alberto Frison                 ...                  \n",
       "\n",
       "  Members_of_the_United_Kingdom_Parliament_for_English_constituencies  \\\n",
       "0                                         Nic Dakin                     \n",
       "1                                   Julian Ridsdale                     \n",
       "2       Stockton South (UK Parliament constituency)                     \n",
       "3                                     Harold Wilson                     \n",
       "4                  Secretary of State for Education                     \n",
       "5                        Labour Government 19451951                     \n",
       "6          Victor Cavendish, 9th Duke of Devonshire                     \n",
       "7                                      Aubrey Jones                     \n",
       "8  Holborn and St Pancras South (UK Parliament co...                    \n",
       "9                                       Roy Jenkins                     \n",
       "\n",
       "                                Living_people            Indian_films  \\\n",
       "0                                  Life peer           Patton (film)    \n",
       "1                            James Callaghan     Munna Bhai M.B.B.S.    \n",
       "2                        Order of succession                 Moojrim    \n",
       "3                                 John Major   Sanjay Leela Bhansali    \n",
       "4                             Martin Stevens              Zor (film)    \n",
       "5  John Boyd-Carpenter, Baron Boyd-Carpenter                   Rekha    \n",
       "6                               Edward Leigh                 Jayaraj    \n",
       "7                             Howard Vincent      Udhayanidhi Stalin    \n",
       "8                    James Barr (politician)                3 Idiots    \n",
       "9    David Howell, Baron Howell of Guildford          Harris Jayaraj    \n",
       "\n",
       "               English-language_albums        Harvard_University_alumni  \\\n",
       "0                Ballad of Easy Rider     Chris Leslie (folk musician)    \n",
       "1        List of Basement Tapes songs                     Powder Alarm    \n",
       "2                       Art Garfunkel                  Augustus Lowell    \n",
       "3                Harvest Moon (album)                     Edgard Varse    \n",
       "4     I Don't Want to Spoil the Party   Presidency of Thomas Jefferson    \n",
       "5                      It Was Written                  Harry Markowitz    \n",
       "6                 Across the Universe              Philosophy of logic    \n",
       "7                    Disturbia (song)                       Guy Lowell    \n",
       "8                    Revolver (album)           Philosophical progress    \n",
       "9  P.S. I Love You (The Beatles song)                   Andrew Jackson    \n",
       "\n",
       "                         People_from_New_York_City  \\\n",
       "0                         Critique of Pure Reason    \n",
       "1                                 Karl Earl Mundt    \n",
       "2                          William Warren Barbour    \n",
       "3                                  Herbert Hoover    \n",
       "4  United States Ambassador to the United Nations    \n",
       "5                     William Maclay (politician)    \n",
       "6                               Stuart Rothenberg    \n",
       "7                                            Howl    \n",
       "8                                          EXCOMM    \n",
       "9                                    Robert Kagan    \n",
       "\n",
       "                         English-language_films  \\\n",
       "0  Eleanor and Franklin: The White House Years    \n",
       "1                         Terror in the Aisles    \n",
       "2                            William S. Cowles    \n",
       "3                              Bruce Greenwood    \n",
       "4    List of Sundance Film Festival selections    \n",
       "5                  A Night at the Opera (film)    \n",
       "6                            Gustave Reininger    \n",
       "7                            Casablanca (film)    \n",
       "8          List of Academy Award-winning films    \n",
       "9                                    High Noon    \n",
       "\n",
       "                            American_films         Black-and-white_films  \\\n",
       "0   List of The Nostalgia Critic episodes   A Night at the Opera (film)    \n",
       "1      Butch Cassidy and the Sundance Kid                Small Soldiers    \n",
       "2                          Haskell Wexler   Monkey Business (1931 film)    \n",
       "3             A Night at the Opera (film)        Animal Crackers (film)    \n",
       "4          Frank Marshall (film producer)                 James Rebhorn    \n",
       "5  The Last House on the Left (2009 film)                  The Bell Boy    \n",
       "6  Golden Globe Award for Best Screenplay                  Virginia Fox    \n",
       "7                               Meg Tilly              Norman Z. McLeod    \n",
       "8                    Walt Disney Pictures                The Cat's Meow    \n",
       "9                            Shawn Wayans                 Up and at 'Em    \n",
       "\n",
       "                      Windows_games  \n",
       "0                Limbo of the Lost   \n",
       "1  Sam & Max Beyond Time and Space   \n",
       "2                Penumbra: Requiem   \n",
       "3              Dragon Age: Origins   \n",
       "4                  Dungeon Runners   \n",
       "5             Aquaria (video game)   \n",
       "6              Atom Zombie Smasher   \n",
       "7                     SimCity 2000   \n",
       "8           Half-Life (video game)   \n",
       "9            The Phantom of Venice   \n",
       "\n",
       "[10 rows x 34 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst=[]\n",
    "for i in block_ranking:\n",
    "    lista=[]\n",
    "    m=0\n",
    "    for s in sorted_nodes[str(i[0])]: #We select just first ten observation to make a little output of our results\n",
    "        if m<10:\n",
    "            lista.append(s[0])\n",
    "            m=m+1\n",
    "    lst.append(lista)\n",
    "for i in lst:\n",
    "    for m in range(0,len(i)): #With this we retrieve the names of the articles corresponding to the indexes\n",
    "        value=int(i[m])-1\n",
    "        i[m]=lista1[value] \n",
    "#And finally...we create a DataFrame        \n",
    "data_tuples = list(zip(lst[0],lst[1],lst[2],lst[3],lst[4],lst[5],lst[6],lst[7],lst[8],lst[9],lst[10],lst[11],lst[12],lst[13],lst[14],lst[15],lst[16],lst[17],lst[18],lst[19],lst[20],lst[21],lst[22],lst[23],lst[24],lst[25],lst[26],lst[27],lst[28],lst[29],lst[30],lst[31],lst[32],lst[33]))\n",
    "df=pd.DataFrame(data_tuples,columns=['Major_League_Baseball_pitchers','Debut_albums','Year_of_death_missing','Year_of_birth_missing_(living_people)','Year_of_birth_missing','Place_of_birth_missing_(living_people)','Asteroids_named_for_people','Main_Belt_asteroids','British_films','Association_football_goalkeepers', 'Article_Feedback_Pilot', 'Rivers_of_Romania',  'English_footballers', 'The_Football_League_players',  'Association_football_forwards',  'Association_football_midfielders', 'Association_football_defenders',  'English_cricketers', 'English_television_actors', 'Fellows_of_the_Royal_Society', 'American_Jews', 'American_television_actors', 'American_film_actors',  'American_military_personnel_of_World_War_II', 'Members_of_the_United_Kingdom_Parliament_for_English_constituencies', 'Living_people', 'Indian_films', 'English-language_albums', 'Harvard_University_alumni', 'People_from_New_York_City', 'English-language_films',\n",
    " 'American_films', 'Black-and-white_films', 'Windows_games'])\n",
    "\n",
    "#It has 34 columns as we have excluded the input category.\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
